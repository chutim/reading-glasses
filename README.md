# reading-glasses

This hackathon-style solo project was built over the course of roughly 2 days, and gave me a chance to try something new and completely on my own. Because it was my first time attempting something solo, my concept was pitched to an instructor to verify its viability.

The overarching goal of this project was to help solve a personal problem: understanding what is in the food I buy. Oftentimes when I'm grocery shopping, I have no idea what some ingredients are on the labels, especially the ones that are just chemical names. I have to pull up a Google search and bushwhack my way through the scientific information to find the health effects I actually care about.

The MVP of this project was to create a mobile app that can take a picture, extract text from the image, and allow the user to then perform an information query. To achieve this, I utilized React Native as the framework to build my app on, the Google Vision API for text extraction, and the E-Additive API for ingredient information. As it was my first time using any of these technologies, it took some effort to get off the ground, but to have something that could function within the amount of time I had was extremely gratifying. Please see the following short video for the user experience.

![Reading Glasses Demo](demo.gif)
